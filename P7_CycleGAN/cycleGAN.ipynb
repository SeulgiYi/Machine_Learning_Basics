{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CycleGAN \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "#import torch.utils.data as data\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "params = {\n",
    "    'batch_size': 1, \n",
    "    'input_size': 256,\n",
    "    'resize_scale': 286,\n",
    "    'crop_size': 256, \n",
    "    'fliplr': True, \n",
    "    'num_epochs': 100, \n",
    "    'decay_epoch':100, \n",
    "    'ngf':32, #number of generator filters\n",
    "    'ndf':64, #number of discriminator filters\n",
    "    'num_resnet': 6, #number of resnet blocks\n",
    "    'lrG': 0.0002, \n",
    "    'lrD': 0.0002, \n",
    "    'beta1': 0.5,   #beta1 for Adam\n",
    "    'beta2': 0.999, #beta2 for Adam\n",
    "    'lambdaA': 10,  #lambdaA for cycle loss\n",
    "    'lambdaB': 10,  #lambdaB for cycle loss    \n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_dir = './data/vangogh2photo'\n",
    "save_dir = './results'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "def to_np(x):\n",
    "    return x.data.cpu().numpy()\n",
    "\n",
    "def plot_train_result(real_image, gen_image, recon_image, epoch, \n",
    "                      save=False, show=True, figsize=(15,15)):\n",
    "    fig,axes = plt.subplots(2, 3, figsize=figsize)\n",
    "    imgs = [to_np(real_image[0]), to_np(gen_image[0]), to_np(recon_image[0]),\n",
    "            to_np(real_image[1]), to_np(gen_image[1]), to_np(recon_image[1])]\n",
    "    for ax, img in zip(axes.flatten(), imgs):\n",
    "        ax.axis('off')\n",
    "        img = img.squeeze()\n",
    "        #img = (((img - img.min()) * 255) / (img.max()-img.min())).transpose(1,2,0).astype(np.int8)\n",
    "        #print(img.min(), img.max())\n",
    "        #img = (((img - (-1)) * 255) / (1-(-1))).transpose(1,2,0).astype(np.int8)\n",
    "        img = (((img - (-1))) / (1-(-1))).transpose(1,2,0)\n",
    "        #print(img.min(), img.max())\n",
    "        ax.imshow(img, cmap=None, aspect='equal')\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    title = 'Epoch {}'.format(epoch+1)\n",
    "    fig.text(0.5, 0.04, title, ha='center')\n",
    "    \n",
    "    if save:\n",
    "        save_fn = save_dir + '/Result_epoch_{:d}.png'.format(epoch+1)\n",
    "        plt.savefig(save_fn)\n",
    "        \n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "class ImagePool():\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "            \n",
    "    def query(self, images):\n",
    "        if self.pool_size == 0:\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images.data:\n",
    "            image = torch.unsqueeze(image, 0)\n",
    "            if self.num_imgs < self.pool_size:\n",
    "                self.num_imgs += 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0,1)\n",
    "                if p > 0.5:\n",
    "                    random_id = random.randint(0, self.pool_size - 1)\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:\n",
    "                    return_images.append(image)\n",
    "        return_images = torch.cat(return_images, 0)\n",
    "        return return_images\n",
    "\n",
    "class DatasetFromFolder(Dataset):\n",
    "    def __init__(self, image_dir, subfolder='train', transform=None,\n",
    "                 resize_scale=None, crop_size=None, fliplr=False):\n",
    "        super(DatasetFromFolder, self).__init__()\n",
    "        self.input_path = os.path.join(image_dir, subfolder)\n",
    "        file_list = sorted(os.listdir(self.input_path))\n",
    "        self.image_filenames = []\n",
    "        for x in file_list:\n",
    "            tmp, ext = os.path.splitext(x)\n",
    "            if ext.lower() == '.jpg':\n",
    "                self.image_filenames.append(x)\n",
    "        #self.image_filenames = [x for x in sorted(os.listdir(self.input_path))]\n",
    "        self.transform = transform\n",
    "        self.resize_scale = resize_scale\n",
    "        self.crop_size = crop_size\n",
    "        self.fliplr = fliplr\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_fn = os.path.join(self.input_path, self.image_filenames[index])\n",
    "        img = Image.open(img_fn).convert('RGB')\n",
    "        \n",
    "        if self.resize_scale:\n",
    "            img = img.resize((self.resize_scale, self.resize_scale), Image.BILINEAR)\n",
    "\n",
    "        if self.crop_size:\n",
    "            x = random.randint(0, self.resize_scale - self.crop_size + 1)\n",
    "            y = random.randint(0, self.resize_scale - self.crop_size + 1)\n",
    "            img = img.crop((x, y, x+self.crop_size, y+self.crop_size))\n",
    "            \n",
    "        if self.fliplr:\n",
    "            if random.random() < 0.5:\n",
    "                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    \n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, input_size, output_size, kernel_size=3, \n",
    "                 stride=2, padding=1, activation='ReLU', normalization=True):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        conv = nn.Conv2d(input_size, output_size, kernel_size, \n",
    "                         stride, padding)\n",
    "        norm_layer = nn.InstanceNorm2d(output_size)\n",
    "        if activation == 'ReLU':\n",
    "            act_func = nn.ReLU(True)\n",
    "        elif activation == 'LeakyReLU':\n",
    "            act_func = nn.LeakyReLU(0.2, True)\n",
    "            \n",
    "        if normalization:\n",
    "            model = [conv, norm_layer, act_func]\n",
    "        else:\n",
    "            model = [conv, act_func]\n",
    "        self.conv_block = nn.Sequential(*model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv_block(x)\n",
    "        \n",
    "        \n",
    "class DeconvBlock(nn.Module):\n",
    "    def __init__(self, input_size, output_size, kernel_size=3, \n",
    "                 stride=2, padding=1, output_padding=1, \n",
    "                 activation='ReLU', normalization=True):\n",
    "        super(DeconvBlock, self).__init__()\n",
    "        deconv = nn.ConvTranspose2d(input_size, output_size, kernel_size, \n",
    "                                    stride, padding, output_padding)\n",
    "        norm_layer = nn.InstanceNorm2d(output_size)\n",
    "        \n",
    "        if activation == 'ReLU':\n",
    "            act_func = nn.ReLU(True)\n",
    "        elif activation == 'LeakyReLU':\n",
    "            act_func = nn.LeakyReLU(0.2, True)\n",
    "        \n",
    "        if normalization:              \n",
    "            model = [deconv, norm_layer, act_func]\n",
    "        else:\n",
    "            model = [deconv, act_func]\n",
    "        self.deconv_block = nn.Sequential(*model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.deconv_block(x)\n",
    "\n",
    "    \n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, num_filter, kernel_size=3, stride=1, padding=0):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        conv = nn.Conv2d(num_filter, num_filter, kernel_size, stride, padding)\n",
    "        norm_layer = nn.InstanceNorm2d(num_filter)\n",
    "        relu = nn.ReLU(True)\n",
    "        pad = nn.ReflectionPad2d(1)\n",
    "        model = [pad, conv, norm_layer, relu, pad, conv, norm_layer]\n",
    "        self.resnet_block = nn.Sequential(*model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.resnet_block(x) + x\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, num_filter, output_dim, num_resnet):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        #Downsampling \n",
    "        model = [nn.ReflectionPad2d(3), \n",
    "                 ConvBlock(input_dim, num_filter, kernel_size=7, stride=1, padding=0),\n",
    "                 ConvBlock(num_filter, num_filter*2), \n",
    "                 ConvBlock(num_filter*2, num_filter*4)]\n",
    "        #Resnet blocks\n",
    "        for i in range(num_resnet):\n",
    "            model += [ResnetBlock(num_filter*4)]\n",
    "        #Upsampling \n",
    "        model += [DeconvBlock(num_filter*4, num_filter*2), \n",
    "                  DeconvBlock(num_filter*2, num_filter),\n",
    "                  nn.ReflectionPad2d(3)]\n",
    "        #Ouput layer\n",
    "        model += [nn.Conv2d(num_filter, output_dim, kernel_size=7, stride=1, padding=0)]\n",
    "        model += [nn.Tanh()]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def normal_weight_init(self,mean=0.0,std=0.02):\n",
    "        for m in self.children():\n",
    "            if isinstance(m,ConvBlock):\n",
    "                nn.init.normal_(m.conv.weight,mean,std)\n",
    "            if isinstance(m,DeconvBlock):\n",
    "                nn.init.normal_(m.deconv.weight,mean,std)\n",
    "            if isinstance(m,ResnetBlock):\n",
    "                nn.init.normal_(m.conv.weight,mean,std)\n",
    "                nn.init.constant_(m.conv.bias,0)\n",
    "\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, num_filter, output_dim, n_layer=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # PatchGAN\n",
    "        model = [ConvBlock(input_dim, num_filter, kernel_size=4, stride=2, padding=1, \n",
    "                           activation='LeakyReLU', normalization=False)]\n",
    "        in_channel = num_filter\n",
    "               \n",
    "        for i in range(n_layer):\n",
    "            out_channel = in_channel * 2\n",
    "            model += [ConvBlock(in_channel, out_channel, kernel_size=4, \n",
    "                                stride=2, padding=1, activation='LeakyReLU')]\n",
    "            in_channel = out_channel\n",
    "        \n",
    "        model += [nn.Conv2d(out_channel, output_dim, kernel_size=4, stride=1, padding=1)]\n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def normal_weight_init(self,mean=0.0,std=0.02):\n",
    "        for m in self.children():\n",
    "            if isinstance(m,ConvBlock):\n",
    "                nn.init.normal_(m.conv.weight,mean,std)\n",
    "            if isinstance(m,DeconvBlock):\n",
    "                nn.init.normal_(m.deconv.weight,mean,std)\n",
    "            if isinstance(m,ResnetBlock):\n",
    "                nn.init.normal_(m.conv.weight,mean,std)\n",
    "                nn.init.constant_(m.conv.bias,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=params['input_size']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load train data\n",
    "train_data_A = DatasetFromFolder(data_dir, subfolder='trainA', transform=transform,\n",
    "                                resize_scale=params['resize_scale'], crop_size=params['crop_size'], fliplr=params['fliplr'])\n",
    "train_data_loader_A = DataLoader(dataset=train_data_A, batch_size=params['batch_size'], shuffle=True)\n",
    "train_data_B = DatasetFromFolder(data_dir, subfolder='trainB', transform=transform,\n",
    "                                resize_scale=params['resize_scale'], crop_size=params['crop_size'], fliplr=params['fliplr'])\n",
    "train_data_loader_B = DataLoader(dataset=train_data_B, batch_size=params['batch_size'], shuffle=True)\n",
    "\n",
    "#Load test data\n",
    "test_data_A = DatasetFromFolder(data_dir, subfolder='testA', transform=transform)\n",
    "test_data_loader_A = DataLoader(dataset=test_data_A, batch_size=params['batch_size'], shuffle=False)\n",
    "test_data_B = DatasetFromFolder(data_dir, subfolder='testB', transform=transform)\n",
    "test_data_loader_B = DataLoader(dataset=test_data_B, batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Get specific test images\n",
    "test_real_A_data = train_data_A.__getitem__(11).unsqueeze(0) # Convert to 4d tensor (BxNxHxW)\n",
    "test_real_B_data = train_data_B.__getitem__(91).unsqueeze(0)\n",
    "\n",
    "#Build Model \n",
    "G_A = Generator(3, params['ngf'], 3, params['num_resnet']).to(device) # input_dim, num_filter, output_dim, num_resnet\n",
    "G_B = Generator(3, params['ngf'], 3, params['num_resnet']).to(device)\n",
    "\n",
    "D_A = Discriminator(3, params['ndf'], 1).to(device) # input_dim, num_filter, output_dim\n",
    "D_B = Discriminator(3, params['ndf'], 1).to(device)\n",
    "\n",
    "G_A.normal_weight_init()\n",
    "G_B.normal_weight_init()\n",
    "D_A.normal_weight_init()\n",
    "D_B.normal_weight_init()\n",
    "\n",
    "G_optimizer = optim.Adam(itertools.chain(G_A.parameters(), G_B.parameters()), lr=params['lrG'], betas=(params['beta1'], params['beta2']))\n",
    "D_A_optimizer = optim.Adam(D_A.parameters(), lr=params['lrD'], betas=(params['beta1'], params['beta2']))\n",
    "D_B_optimizer = optim.Adam(D_B.parameters(), lr=params['lrD'], betas=(params['beta1'], params['beta2']))\n",
    "\n",
    "MSE_Loss = nn.MSELoss().to(device)\n",
    "L1_Loss = nn.L1Loss().to(device)\n",
    "\n",
    "# # Training GAN\n",
    "D_A_avg_losses = []\n",
    "D_B_avg_losses = []\n",
    "G_A_avg_losses = []\n",
    "G_B_avg_losses = []\n",
    "cycle_A_avg_losses = []\n",
    "cycle_B_avg_losses = []\n",
    "\n",
    "# Generated image pool\n",
    "num_pool = 50\n",
    "fake_A_pool = ImagePool(num_pool)\n",
    "fake_B_pool = ImagePool(num_pool)\n",
    "\n",
    "step = 0\n",
    "for epoch in range(params['num_epochs']):\n",
    "    D_A_losses = []\n",
    "    D_B_losses = []\n",
    "    G_A_losses = []\n",
    "    G_B_losses = []\n",
    "    cycle_A_losses = []\n",
    "    cycle_B_losses = []\n",
    "    \n",
    "    # Learing rate decay \n",
    "    if(epoch + 1) > params['decay_epoch']:\n",
    "        D_A_optimizer.param_groups[0]['lr'] -= params['lrD'] / (params['num_epochs'] - params['decay_epoch'])\n",
    "        D_B_optimizer.param_groups[0]['lr'] -= params['lrD'] / (params['num_epochs'] - params['decay_epoch'])\n",
    "        G_optimizer.param_groups[0]['lr'] -= params['lrG'] / (params['num_epochs'] - params['decay_epoch'])\n",
    "        \n",
    "    \n",
    "    # training \n",
    "    for i, (real_A, real_B) in enumerate(zip(train_data_loader_A, train_data_loader_B)):\n",
    "        \n",
    "        # input image data\n",
    "        real_A = real_A.to(device)\n",
    "        real_B = real_B.to(device)\n",
    "        \n",
    "        # train generator G: A->B\n",
    "        fake_B = G_A(real_A)\n",
    "        D_B_fake_decision = D_B(fake_B)\n",
    "        G_A_loss = MSE_Loss(D_B_fake_decision, torch.ones(D_B_fake_decision.size()).to(device))\n",
    "        \n",
    "        # forward cycle loss\n",
    "        recon_A = G_B(fake_B)\n",
    "        cycle_A_loss = L1_Loss(recon_A, real_A) * params['lambdaA']\n",
    "        \n",
    "        # train generator F: B -> A\n",
    "        fake_A = G_B(real_B)\n",
    "        D_A_fake_decision = D_A(fake_A)\n",
    "        G_B_loss = MSE_Loss(D_A_fake_decision, torch.ones(D_A_fake_decision.size()).to(device))\n",
    "        \n",
    "        # backward cycle loss\n",
    "        recon_B = G_A(fake_A)\n",
    "        cycle_B_loss = L1_Loss(recon_B, real_B) * params['lambdaB']\n",
    "        \n",
    "        # Back propagation\n",
    "        G_loss = G_A_loss + G_B_loss + cycle_A_loss + cycle_B_loss\n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        \n",
    "        \n",
    "        # train discriminator D_A \n",
    "        D_A_real_decision = D_A(real_A)\n",
    "        D_A_real_loss = MSE_Loss(D_A_real_decision, torch.ones(D_A_real_decision.size()).to(device))\n",
    "        \n",
    "        fake_A = fake_A_pool.query(fake_A)\n",
    "        \n",
    "        D_A_fake_decision = D_A(fake_A.detach())\n",
    "        D_A_fake_loss = MSE_Loss(D_A_fake_decision, torch.zeros(D_A_fake_decision.size()).to(device))\n",
    "        \n",
    "        # Back propagation\n",
    "        D_A_loss = (D_A_real_loss + D_A_fake_loss) * 0.5\n",
    "        D_A_optimizer.zero_grad()\n",
    "        D_A_loss.backward()\n",
    "        D_A_optimizer.step()\n",
    "        \n",
    "        # train discriminator D_B \n",
    "        D_B_real_decision = D_B(real_B)\n",
    "        D_B_real_loss = MSE_Loss(D_B_real_decision, torch.ones(D_B_fake_decision.size()).to(device))\n",
    "        \n",
    "        fake_B = fake_B_pool.query(fake_B)\n",
    "        \n",
    "        D_B_fake_decision = D_B(fake_B.detach())\n",
    "        D_B_fake_loss = MSE_Loss(D_B_fake_decision, torch.zeros(D_B_fake_decision.size()).to(device))\n",
    "        \n",
    "        # Back propagation\n",
    "        D_B_loss = (D_B_real_loss + D_B_fake_loss) * 0.5\n",
    "        D_B_optimizer.zero_grad()\n",
    "        D_B_loss.backward()\n",
    "        D_B_optimizer.step()\n",
    "        \n",
    "        # loss values\n",
    "        D_A_losses.append(D_A_loss.item())\n",
    "        D_B_losses.append(D_B_loss.item())\n",
    "        G_A_losses.append(G_A_loss.item())\n",
    "        G_B_losses.append(G_B_loss.item())\n",
    "        cycle_A_losses.append(cycle_A_loss.item())\n",
    "        cycle_B_losses.append(cycle_B_loss.item())\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print('Epoch:[{}/{}], Step [{}/{}], D_A_loss: {:.4f}, D_B_loss: {:.4f}, G_A_loss: {:.4f}, G_B_loss: {:.4f}'\n",
    "                  .format(epoch+1, params['num_epochs'], i+1, len(train_data_loader_A), \n",
    "                          D_A_loss.item(), D_B_loss.item(), G_A_loss.item(), G_B_loss.item()))\n",
    "            \n",
    "        step += 1\n",
    "        \n",
    "    D_A_avg_loss = torch.mean(torch.FloatTensor(D_A_losses))\n",
    "    D_B_avg_loss = torch.mean(torch.FloatTensor(D_B_losses))\n",
    "    G_A_avg_loss = torch.mean(torch.FloatTensor(G_A_losses))\n",
    "    G_B_avg_loss = torch.mean(torch.FloatTensor(G_B_losses))\n",
    "    cycle_A_avg_loss = torch.mean(torch.FloatTensor(cycle_A_losses))\n",
    "    cycle_B_avg_loss = torch.mean(torch.FloatTensor(cycle_B_losses))\n",
    "\n",
    "    # avg loss values for plot\n",
    "    D_A_avg_losses.append(D_A_avg_loss.item())\n",
    "    D_B_avg_losses.append(D_B_avg_loss.item())\n",
    "    G_A_avg_losses.append(G_A_avg_loss.item())\n",
    "    G_B_avg_losses.append(G_B_avg_loss.item())\n",
    "    cycle_A_avg_losses.append(cycle_A_avg_loss.item())\n",
    "    cycle_B_avg_losses.append(cycle_B_avg_loss.item())\n",
    "    \n",
    "    # Show result for test image\n",
    "    test_real_A = test_real_A_data.to(device)\n",
    "    test_fake_B = G_A(test_real_A)\n",
    "    test_recon_A = G_B(test_fake_B)\n",
    "\n",
    "    test_real_B = test_real_B_data.to(device)\n",
    "    test_fake_A = G_B(test_real_B)\n",
    "    test_recon_B = G_A(test_fake_A)\n",
    "    \n",
    "\n",
    "    plot_train_result([test_real_A, test_real_B], [test_fake_B, test_fake_A], [test_recon_A, test_recon_B],\n",
    "                            epoch, save=True)\n",
    "\n",
    "all_losses = pd.DataFrame()\n",
    "all_losses['D_A_avg_losses'] = D_A_avg_losses\n",
    "all_losses['D_B_avg_losses'] = D_B_avg_losses\n",
    "all_losses['G_A_avg_losses'] = G_A_avg_losses\n",
    "all_losses['G_B_avg_losses'] = G_B_avg_losses\n",
    "all_losses['cycle_A_avg_losses'] = cycle_A_avg_losses\n",
    "all_losses['cycle_B_avg_losses'] = cycle_B_avg_losses\n",
    "all_losses.to_csv('avg_losses',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
